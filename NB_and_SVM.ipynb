{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import spacy\n",
    "#pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "#import en_core_web_sm\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>this be so cool -PRON- be like ' would -PRON- ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>thank -PRON- this would make -PRON- life a lot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>this be such an urgent design problem kudo to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>be this something i will be able to install on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>haha -PRON- guy be a bunch of loser</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       comment_text  target\n",
       "0  59848  this be so cool -PRON- be like ' would -PRON- ...       0\n",
       "1  59849  thank -PRON- this would make -PRON- life a lot...       0\n",
       "2  59852  this be such an urgent design problem kudo to ...       0\n",
       "3  59855  be this something i will be able to install on...       0\n",
       "4  59856                haha -PRON- guy be a bunch of loser       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv(\"data/comments_preprocessed_final.csv\")\n",
    "comments_5k = comments.iloc[:5000,]\n",
    "comments_5k.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = comments_5k.comment_text\n",
    "#y = comments_5k.target\n",
    "X = comments.comment_text\n",
    "y = comments.target\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910564238160442\n"
     ]
    }
   ],
   "source": [
    "# use count vectorizer\n",
    "# partly retreived from https://www.kaggle.com/catris25/multinomial-naive-bayes-with-countvectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_valid = vectorizer.transform(X_valid)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_valid)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has n_samples: 1235441, n_features: 198843\n",
      "X_valid has n_samples: 529475, n_features: 198843\n",
      "accuracy:   0.921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96    487019\n",
      "           1       0.89      0.02      0.04     42456\n",
      "\n",
      "    accuracy                           0.92    529475\n",
      "   macro avg       0.91      0.51      0.50    529475\n",
      "weighted avg       0.92      0.92      0.89    529475\n",
      "\n",
      "confusion matrix:\n",
      "[[486914    105]\n",
      " [ 41587    869]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# use tf-idf\n",
    "# retreived from https://iq.opengenus.org/naive-bayes-on-tf-idf-vectorized-matrix/\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train)\n",
    "X_valid_tf = tf_vectorizer.transform(X_valid)\n",
    "print(\"X_train has n_samples: %d, n_features: %d\" % X_train_tf.shape)\n",
    "print(\"X_valid has n_samples: %d, n_features: %d\" % X_valid_tf.shape)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tf, y_train)\n",
    "y_pred = mnb.predict(X_valid_tf)\n",
    "\n",
    "score = metrics.accuracy_score(y_valid, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated scores: [0.90394749 0.90314831 0.90901545 0.89723868 0.90089891]\n",
      "Mean cross validated scores: 0.9028497667323991\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation for count vectorizer\n",
    "X_cv = vectorizer.fit_transform(X)\n",
    "scores_5fd = cross_val_score(mnb, X_cv, y, cv=5)\n",
    "print(\"Cross validated scores:\", scores_5fd)\n",
    "print(\"Mean cross validated scores:\", scores_5fd.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has n_samples: 1764916, n_features: 238205\n",
      "Cross validated scores: [0.92109557 0.92072989 0.92061657 0.92088854 0.92093954]\n",
      "Mean cross validated scores: 0.9208540235107222\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation for tfidf\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer() \n",
    "\n",
    "X_tf = tf_vectorizer.fit_transform(X)\n",
    "#X_valid_tf = tf_vectorizer.transform(X_valid)\n",
    "print(\"X_train has n_samples: %d, n_features: %d\" % X_tf.shape)\n",
    "#print(\"X_valid has n_samples: %d, n_features: %d\" % X_valid_tf.shape)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "scores_5fd = cross_val_score(mnb, X_tf, y, cv=5)\n",
    "print(\"Cross validated scores:\", scores_5fd)\n",
    "print(\"Mean cross validated scores:\", scores_5fd.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    cited from scikit-learn...\n",
    "    Using pipeline and grid search to tune parameters of vectorization, feature selection and model fitting. \n",
    "'''\n",
    "pipeline = Pipeline([\n",
    "                    ('vect', CountVectorizer(stop_words='english')), \n",
    "                    ('kbest', SelectKBest()), \n",
    "    # why mutual_info_classif, not f_classifier: https://medium.com/@hertan06/which-features-to-use-in-your-model-350630a1e31c\n",
    "                     ('clf', SGDClassifier(random_state=100)), \n",
    "                    ])\n",
    "parameters={\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), \n",
    "    'kbest__score_func': (mutual_info_classif, chi2, f_classif),\n",
    "    'kbest__k': (1000,2000,'all'),\n",
    "    #'clf__alpha': [1e-7, 1e0],\n",
    "    #'clf__alpha': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    # C / alpha overfits or not.\n",
    "    'clf__penalty': ('l2', 'l1'), #l2: ridge regression\n",
    "    'clf__loss': ('hinge', 'log') #hinge (Default): a linear SVM, log: logistic regression\n",
    "    \n",
    "}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    grid_search=GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    \n",
    "    grid_search.fit(X_train_tidy, y_train)\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    \n",
    "    results = grid_search.cv_results_\n",
    "    test_scores = results['mean_test_score']\n",
    "    params = results['params']\n",
    "    rank = results['rank_test_score']\n",
    "    \n",
    "    print(\"best score: %0.3f\" % grid_search.best_score_)\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    print(\"Best parameters set: \")\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    print(\"Top 5 best parameter sets based on accuracy score: \")\n",
    "    list(np.take(params,list(rank.argsort()[:5])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the parameter sets that gives the highest accuracy score\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the top three parameter sets have similar accuracy\n",
    "np.take(test_scores, list(rank.argsort()[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "test_scores = results['mean_test_score']\n",
    "params = results['params']\n",
    "rank = results['rank_test_score']\n",
    "print(\"Top 5 best parameter sets based on accuracy score: \")\n",
    "list(np.take(params,list(rank.argsort()[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcuate train & test accuracy using tuned parameters\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_tidy_vec = vectorizer.fit_transform(X_train_tidy)\n",
    "\n",
    "vocab_train1, vocab_val1, y_vocab_train1, y_vocab_val1 = train_test_split(X_train_tidy_vec, y_train, test_size=0.3, random_state = 100)\n",
    "\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "fs_train = fs.fit(vocab_train1, y_vocab_train)\n",
    "transformer_train = fs.transform(vocab_train1)\n",
    "transformer_val = fs.transform(vocab_val1)\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log', penalty='l1').fit(transformer_train, y_vocab_train1)\n",
    "print(\"Accuracy after parameter tunning: \")\n",
    "print(\"train accuracy: \", cross_val_score(sgd_clf, transformer_train, y_vocab_train1).mean())\n",
    "print(\"test accuracy: \", cross_val_score(sgd_clf, transformer_val, y_vocab_val1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Source: scikit-learn... , \n",
    "    Validation curve shows the accuracy score of using different regularization parameter values\n",
    "'''\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "train_scores, test_scores = validation_curve(SGDClassifier(loss='log', penalty='l1'), \n",
    "                                             X_train_tidy_vec, y_train, \"alpha\", \n",
    "                                             np.logspace(-15, 0, 50),\n",
    "                                             cv = 5, n_jobs=-1, verbose=10)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "param_range = np.logspace(-15, 0, 50)\n",
    "plt.title(\"Validation Curve for Linear Regression\")\n",
    "plt.xlabel(\"Log alpha value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.ylim(0.8, 1.05)\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# finding the value C with the highest validation accuracy score\n",
    "best_alpha = param_range[test_scores_mean.argmax()]\n",
    "print(\"best log alpha value:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Code cited from scikit-learn/Plotting Learning Curves... \n",
    "    Learning curve is plotted to show how well a model can learn from the data. \n",
    "    Closer the validation score is to the training score, better the model is. \n",
    "'''\n",
    "train_size, learn_train, learn_test = learning_curve(SGDClassifier(loss='log', penalty='l1', alpha = best_alpha),  \n",
    "                                                    X_train_tidy_vec, y_train, \n",
    "                                                    train_sizes = np.linspace(0.00001,1,50), \n",
    "                                                    cv = 5, n_jobs=-1, verbose=10)\n",
    "mean_learn_train = np.mean(learn_train, axis=1)\n",
    "std_learn_train = np.std(learn_train, axis=1)\n",
    "mean_learn_test = np.mean(learn_test, axis=1)\n",
    "std_learn_test = np.std(learn_test, axis=1)\n",
    "\n",
    "train_sizes = np.linspace(0.000001,1,50)\n",
    "plt.title(\"Learning Curve for Linear Regression\")\n",
    "plt.xlabel(\"training examples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.ylim(0.9, 1.05)\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_sizes, mean_learn_train, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(train_sizes, mean_learn_train - std_learn_train,\n",
    "                 mean_learn_train + std_learn_train, alpha=0.1,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(train_sizes, mean_learn_test, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(train_sizes, mean_learn_test - std_learn_test,\n",
    "                 mean_learn_test + std_learn_test, alpha=0.1,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, \n",
    "    grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
