{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_train = pd.read_csv(r'../data/train.csv')\n",
    "X = df_train.comment_text\n",
    "y = df_train.target.apply(lambda x: 'toxic' if x >= 0.5 else 'non-toxic')\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 17)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis = 1) # training set\n",
    "\n",
    "# separate toxic and non-toxic instances\n",
    "non_toxic = train[train.target == 'non-toxic']\n",
    "toxic = train[train.target == 'toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Handling imbalanced data\n",
    "## 1.1 Oversampling minority class (toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you donâ€™t have a ton of data to work with.\n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "Important Note:\n",
    "Always split into test and train sets BEFORE trying oversampling techniques! Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets. This can allow our model to simply memorize specific data points and cause overfitting and poor generalization to the test data.\" (Boyle, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample minority class\n",
    "toxic_oversampled = resample(toxic,\n",
    "                          replace = True, # sample with replacement\n",
    "                          n_samples = len(non_toxic), # match the size of non-toxic set\n",
    "                          random_state = 27)\n",
    "\n",
    "# training set combined with non_toxic and oversampled toxic instances\n",
    "train_oversampled = pd.concat([not_toxic, toxic_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'non-toxic': 1328440, 'toxic': 1328440})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size\n",
    "Counter(train_oversampled.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Undersampling majority class (non-toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback is that we are removing information that may be valuable. This could lead to underfitting and poor generalization to the test set.\n",
    "We will again use the resampling module from Scikit-Learn to randomly remove samples from the majority class.\" (Boyle, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample majority class\n",
    "non_toxic_undersampled = resample(non_toxic,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(toxic), # match the size of toxic set\n",
    "                                random_state = 17)\n",
    "\n",
    "# training set combined with toxic and undersampled non-toxic instances\n",
    "train_undersampled = pd.concat([non_toxic_undersampled, toxic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'non-toxic': 115459, 'toxic': 115459})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size\n",
    "Counter(train_undersampled.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Boyle, T..(2019).https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
